{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73577a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"I love nlp\", \"I teach genai\", \"I am working in IT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "590ec977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IT', 'nlp', 'genai', 'in', 'teach', 'am', 'working', 'love', 'I']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = list(set(\" \".join(corpus).split()))\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f6b13b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'IT')\n",
      "(1, 'nlp')\n",
      "(2, 'genai')\n",
      "(3, 'in')\n",
      "(4, 'teach')\n",
      "(5, 'am')\n",
      "(6, 'working')\n",
      "(7, 'love')\n",
      "(8, 'I')\n"
     ]
    }
   ],
   "source": [
    "for i in enumerate(unique_words):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db144db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IT': 0,\n",
       " 'nlp': 1,\n",
       " 'genai': 2,\n",
       " 'in': 3,\n",
       " 'teach': 4,\n",
       " 'am': 5,\n",
       " 'working': 6,\n",
       " 'love': 7,\n",
       " 'I': 8}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index = {word:i for i, word in enumerate(unique_words)}\n",
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27ae173a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I love nlp', 'I teach genai', 'I am working in IT']\n",
      "['I love nlp', 'I teach genai', 'I am working in IT']\n",
      "['I love nlp', 'I teach genai', 'I am working in IT']\n"
     ]
    }
   ],
   "source": [
    "one_hot_vector = []\n",
    "for sentence in corpus :\n",
    "    print(corpus)\n",
    "    sentence_vector = []\n",
    "    for word in sentence.split():\n",
    "        vector = [0] * len(unique_words)\n",
    "        #print(vector)\n",
    "        vector[word_to_index[word]] =1 \n",
    "        sentence_vector.append(vector)\n",
    "    one_hot_vector.append(sentence_vector)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80f9a5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "  [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0]]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d761f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\"text\",4,5,6,7,87 , \"king\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1344f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "l[0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35a8224d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 5, 6, 7, 87, 'king']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397716c6",
   "metadata": {},
   "source": [
    "Drawback of one hot vector\n",
    "1. Lenght of the vector space is equal to total no unique words\n",
    "2. Sparse Matrix/data\n",
    "3. More memory space\n",
    "4. for small dataset it has created 3 *10 dimential matrix\n",
    "5. large vocabulary = vector size will get increase\n",
    "6. No where maintaining the relationship between data\n",
    "7. no contexual meaning of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59253691",
   "metadata": {},
   "source": [
    "Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d5ccefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No of times word occured in the \n",
    "#Frequency based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f8f07f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "034f089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=None,vocabulary=unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a5da6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"I love nlp nlp nlp nlp\", \"I teach genai\", \"I am working in IT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33bcdbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "936588f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 4, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc697497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IT', 'nlp', 'genai', 'in', 'teach', 'am', 'working', 'love', 'I'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89983d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to ohe\n",
    "# but lenght of the vector is equal to unique words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc83b31",
   "metadata": {},
   "source": [
    "TFIDF : Term Frequency - inverse document frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce903736",
   "metadata": {},
   "source": [
    "TF = Number_of_times_word_appeared_in_the_doc/ total_no_of_word_in_doc \n",
    "\n",
    "IDF = LOG(Total_No_Of_Doc/no_of_doc_containing_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3346e350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love nlp nlp nlp nlp', 'I teach genai', 'I am working in IT']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61d15aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55307a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tf_idf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2dbc701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vect_tf_idf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0697ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.24253563,\n",
       "        0.9701425 , 0.        , 0.        ],\n",
       "       [0.        , 0.70710678, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.70710678, 0.        ],\n",
       "       [0.5       , 0.        , 0.5       , 0.5       , 0.        ,\n",
       "        0.        , 0.        , 0.5       ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b69ba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IT will reduce the impact of those words which are appearing very very frequently\n",
    "#if the words are unique it will give higher weitage\n",
    "# gives more important to the rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c5e7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not able to caputure the order/context of the word\n",
    "# computationly expensive bcoz of the calculation\n",
    "# still it is creting the sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9f19b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
